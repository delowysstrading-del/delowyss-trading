# main.py - V5.5 ULTRA EFICIENTE CORREGIDO - PREDICCI√ìN 55s-60s
"""
Delowyss Trading AI ‚Äî V5.5 ULTRA EFICIENTE CON PREDICCI√ìN EN 55s-60s
CEO: Eduardo Solis ‚Äî ¬© 2025
"""

import os
import time
import threading
import logging
from datetime import datetime
from collections import deque
import numpy as np
import pandas as pd
import json
import joblib

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse

# ------------------ CONFIGURACI√ìN OPTIMIZADA ------------------
IQ_EMAIL = os.getenv("IQ_EMAIL")
IQ_PASSWORD = os.getenv("IQ_PASSWORD")
PAR = "EURUSD"
TIMEFRAME = int(os.getenv("TIMEFRAME", "60"))
PREDICTION_WINDOW = int(os.getenv("PREDICTION_WINDOW", "5"))  # ‚úÖ PREDICCI√ìN 55s-60s
MIN_TICKS_FOR_PREDICTION = int(os.getenv("MIN_TICKS_FOR_PREDICTION", "8"))
TICK_BUFFER_SIZE = int(os.getenv("TICK_BUFFER_SIZE", "150"))
PORT = int(os.getenv("PORT", "10000"))

# Model paths
MODEL_DIR = os.getenv("MODEL_DIR", "models")
os.makedirs(MODEL_DIR, exist_ok=True)
ONLINE_MODEL_PATH = os.path.join(MODEL_DIR, "online_sgd_ultra.pkl")
ONLINE_SCALER_PATH = os.path.join(MODEL_DIR, "online_scaler_ultra.pkl")

# ---------------- LOGGING OPTIMIZADO ----------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[logging.StreamHandler()]
)

def now_iso():
    return datetime.utcnow().isoformat() + 'Z'

# ------------------ IA ULTRA EFICIENTE (MISMO C√ìDIGO ANTERIOR) ------------------
class UltraEfficientAnalyzer:
    def __init__(self):
        self.ticks = deque(maxlen=TICK_BUFFER_SIZE)
        self.current_candle_open = None
        self.current_candle_high = None
        self.current_candle_low = None
        self.current_candle_close = None
        self.tick_count = 0
        self.price_memory = deque(maxlen=80)
        
        self.velocity_metrics = deque(maxlen=30)
        self.acceleration_metrics = deque(maxlen=20)
        self.volume_profile = deque(maxlen=15)
        self.price_levels = deque(maxlen=10)
        
        self.candle_start_time = None
        self.analysis_phases = {
            'initial': {'ticks': 0, 'analysis': {}, 'weight': 0.2},
            'middle': {'ticks': 0, 'analysis': {}, 'weight': 0.3},
            'final': {'ticks': 0, 'analysis': {}, 'weight': 0.5}
        }
        self.phase_accuracy = {'initial': 0.6, 'middle': 0.7, 'final': 0.9}
        
    def add_tick(self, price: float, seconds_remaining: float = None):
        try:
            price = float(price)
            current_time = time.time()
            
            if self.current_candle_open is None:
                self.current_candle_open = self.current_candle_high = self.current_candle_low = price
                self.candle_start_time = current_time
                logging.info("üïØÔ∏è Nueva vela iniciada - An√°lisis ultra eficiente activado")
            
            self.current_candle_high = max(self.current_candle_high, price)
            self.current_candle_low = min(self.current_candle_low, price)
            self.current_candle_close = price
            
            tick_data = {
                'price': price,
                'timestamp': current_time,
                'volume': 1,
                'microtimestamp': current_time * 1000,
                'seconds_remaining': seconds_remaining,
                'candle_age': current_time - self.candle_start_time if self.candle_start_time else 0
            }
            
            self.ticks.append(tick_data)
            self.price_memory.append(price)
            self.tick_count += 1
            
            self._calculate_ultra_metrics(tick_data)
            self._analyze_optimized_phases(tick_data)
            
            return tick_data
        except Exception as e:
            logging.error(f"Error en add_tick: {e}")
            return None
    
    def _calculate_ultra_metrics(self, current_tick):
        if len(self.ticks) < 2:
            return
            
        try:
            current_price = current_tick['price']
            current_time = current_tick['timestamp']
            
            previous_tick = list(self.ticks)[-2]
            time_diff = current_time - previous_tick['timestamp']
            if time_diff > 0:
                price_diff = current_price - previous_tick['price']
                velocity = price_diff / time_diff
                
                self.velocity_metrics.append({
                    'velocity': velocity,
                    'timestamp': current_time,
                    'price_change': price_diff
                })
            
            if len(self.velocity_metrics) >= 2:
                current_velocity = self.velocity_metrics[-1]['velocity']
                previous_velocity = self.velocity_metrics[-2]['velocity']
                velocity_time_diff = current_time - self.velocity_metrics[-2]['timestamp']
                
                if velocity_time_diff > 0:
                    acceleration = (current_velocity - previous_velocity) / velocity_time_diff
                    self.acceleration_metrics.append({
                        'acceleration': acceleration,
                        'timestamp': current_time
                    })
            
            if len(self.ticks) >= 8:
                recent_ticks = list(self.ticks)[-8:]
                price_changes = [tick['price'] for tick in recent_ticks]
                if price_changes:
                    avg_price = np.mean(price_changes)
                    self.volume_profile.append({
                        'avg_price': avg_price,
                        'tick_count': len(recent_ticks),
                        'timestamp': current_time
                    })
            
            if len(self.price_memory) >= 12:
                prices = list(self.price_memory)
                resistance = max(prices[-12:])
                support = min(prices[-12:])
                self.price_levels.append({
                    'resistance': resistance,
                    'support': support,
                    'timestamp': current_time
                })
                
        except Exception as e:
            logging.debug(f"Error en c√°lculo de m√©tricas: {e}")
    
    def _analyze_optimized_phases(self, tick_data):
        candle_age = tick_data['candle_age']
        
        if candle_age < 20:
            self.analysis_phases['initial']['ticks'] += 1
            if self.analysis_phases['initial']['ticks'] % 8 == 0:
                self.analysis_phases['initial']['analysis'] = self._get_phase_analysis_optimized('initial')
                
        elif candle_age < 40:
            self.analysis_phases['middle']['ticks'] += 1
            if self.analysis_phases['middle']['ticks'] % 6 == 0:
                self.analysis_phases['middle']['analysis'] = self._get_phase_analysis_optimized('middle')
                
        else:
            self.analysis_phases['final']['ticks'] += 1
            if self.analysis_phases['final']['ticks'] % 3 == 0:
                self.analysis_phases['final']['analysis'] = self._get_phase_analysis_optimized('final')
    
    def _get_phase_analysis_optimized(self, phase):
        try:
            if phase == 'initial':
                ticks = list(self.ticks)[:20] if len(self.ticks) >= 20 else list(self.ticks)
            elif phase == 'middle':
                ticks = list(self.ticks)[20:40] if len(self.ticks) >= 40 else list(self.ticks)[20:]
            else:
                ticks = list(self.ticks)[40:] if len(self.ticks) >= 40 else []
            
            if not ticks:
                return {}
            
            prices = [tick['price'] for tick in ticks]
            price_changes = [prices[i] - prices[i-1] for i in range(1, len(prices))]
            
            volatility = (max(prices) - min(prices)) * 10000 if prices else 0
            avg_price = np.mean(prices) if prices else 0
            
            if len(prices) >= 5:
                recent_trend = np.polyfit(range(5), prices[-5:], 1)[0] * 10000
            else:
                recent_trend = (prices[-1] - prices[0]) * 10000 if len(prices) > 1 else 0
            
            if price_changes:
                positive_changes = len([x for x in price_changes if x > 0])
                total_changes = len(price_changes)
                buy_pressure = positive_changes / total_changes
                
                magnitude_changes = sum(abs(x) for x in price_changes)
                if magnitude_changes > 0:
                    buy_magnitude = sum(x for x in price_changes if x > 0) / magnitude_changes
                else:
                    buy_magnitude = 0.5
                    
                combined_pressure = (buy_pressure * 0.6 + buy_magnitude * 0.4)
            else:
                combined_pressure = 0.5
            
            return {
                'avg_price': avg_price,
                'volatility': volatility,
                'trend': 'ALCISTA' if recent_trend > 0.1 else 'BAJISTA' if recent_trend < -0.1 else 'LATERAL',
                'trend_strength': abs(recent_trend),
                'buy_pressure': combined_pressure,
                'tick_count': len(ticks),
                'phase_accuracy': self.phase_accuracy[phase]
            }
        except Exception as e:
            logging.debug(f"Error en an√°lisis de fase {phase}: {e}")
            return {}
    
    def _calculate_ultra_advanced_metrics(self):
        if len(self.price_memory) < 8:
            return {}
            
        try:
            prices = np.array(list(self.price_memory))
            
            trend_metrics = []
            for window in [5, 10, 15]:
                if len(prices) >= window:
                    trend = np.polyfit(range(window), prices[-window:], 1)[0] * 10000
                    trend_metrics.append(trend)
            
            if trend_metrics:
                weights = [0.2, 0.3, 0.5] if len(trend_metrics) == 3 else [1.0]
                trend_strength = np.average(trend_metrics, weights=weights[:len(trend_metrics)])
            else:
                trend_strength = (prices[-1] - prices[0]) * 10000 if len(prices) > 1 else 0
            
            momentum_metrics = []
            for period in [3, 6, 9]:
                if len(prices) >= period:
                    momentum = (prices[-1] - prices[-period]) * 10000
                    momentum_metrics.append(momentum)
            
            if momentum_metrics:
                momentum = np.mean(momentum_metrics)
            else:
                momentum = 0
            
            if len(prices) >= 10:
                early_vol = (max(prices[:5]) - min(prices[:5])) * 10000
                late_vol = (max(prices[-5:]) - min(prices[-5:])) * 10000
                volatility = (early_vol * 0.3 + late_vol * 0.7)
            else:
                volatility = (max(prices) - min(prices)) * 10000
            
            if len(self.ticks) > 8:
                recent_ticks = list(self.ticks)[-8:]
                price_changes = []
                for i in range(1, len(recent_ticks)):
                    change = recent_ticks[i]['price'] - recent_ticks[i-1]['price']
                    price_changes.append(change)
                
                if price_changes:
                    positive = len([x for x in price_changes if x > 0])
                    negative = len([x for x in price_changes if x < 0])
                    total = len(price_changes)
                    
                    buy_pressure = positive / total
                    sell_pressure = negative / total
                    
                    if sell_pressure > 0:
                        pressure_ratio = buy_pressure / sell_pressure
                    else:
                        pressure_ratio = 10.0 if buy_pressure > 0 else 1.0
                        
                    buy_magnitude = sum(x for x in price_changes if x > 0)
                    sell_magnitude = abs(sum(x for x in price_changes if x < 0))
                    
                    if sell_magnitude > 0:
                        magnitude_ratio = buy_magnitude / sell_magnitude
                    else:
                        magnitude_ratio = 10.0 if buy_magnitude > 0 else 1.0
                    
                    combined_ratio = (pressure_ratio * 0.6 + magnitude_ratio * 0.4)
                else:
                    buy_pressure = sell_pressure = combined_ratio = 0.5
            else:
                buy_pressure = sell_pressure = combined_ratio = 0.5
            
            avg_velocity = 0
            if self.velocity_metrics:
                velocities = [v['velocity'] for v in self.velocity_metrics]
                avg_velocity = np.mean(velocities) * 10000
            
            phase_analysis = self._combine_phase_analysis_optimized()
            
            market_phase = self._determine_market_phase_optimized(
                trend_strength, volatility, phase_analysis
            )
            
            data_quality = min(1.0, self.tick_count / 20.0)
            
            return {
                'trend_strength': trend_strength,
                'momentum': momentum,
                'volatility': volatility,
                'buy_pressure': buy_pressure,
                'sell_pressure': sell_pressure,
                'pressure_ratio': combined_ratio,
                'market_phase': market_phase,
                'data_quality': data_quality,
                'velocity': avg_velocity,
                'phase_analysis': phase_analysis,
                'candle_progress': (time.time() - self.candle_start_time) / TIMEFRAME if self.candle_start_time else 0,
                'total_ticks': self.tick_count,
                'confidence_score': self._calculate_confidence_score()
            }
        except Exception as e:
            logging.error(f"Error en c√°lculo de m√©tricas avanzadas: {e}")
            return {}
    
    def _combine_phase_analysis_optimized(self):
        try:
            initial = self.analysis_phases['initial']['analysis']
            middle = self.analysis_phases['middle']['analysis']
            final = self.analysis_phases['final']['analysis']
            
            weights = {
                'initial': self.analysis_phases['initial']['weight'],
                'middle': self.analysis_phases['middle']['weight'], 
                'final': self.analysis_phases['final']['weight']
            }
            
            trends = []
            strengths = []
            pressures = []
            
            for phase, data in [('initial', initial), ('middle', middle), ('final', final)]:
                if data.get('trend'):
                    trends.append((data['trend'], weights[phase]))
                    strengths.append(data.get('trend_strength', 0) * weights[phase])
                    pressures.append(data.get('buy_pressure', 0.5) * weights[phase])
            
            if trends:
                alcista_weight = sum(weight for trend, weight in trends if trend == 'ALCISTA')
                bajista_weight = sum(weight for trend, weight in trends if trend == 'BAJISTA')
                
                if alcista_weight > bajista_weight:
                    combined_trend = 'ALCISTA'
                elif bajista_weight > alcista_weight:
                    combined_trend = 'BAJISTA'
                else:
                    combined_trend = 'LATERAL'
            else:
                combined_trend = 'N/A'
            
            combined = {
                'trend': combined_trend,
                'trend_strength': sum(strengths) if strengths else 0,
                'buy_pressure': sum(pressures) if pressures else 0.5,
                'momentum_shift': len(set(trend for trend, _ in trends)) > 1 if trends else False,
                'consistency_score': alcista_weight if combined_trend == 'ALCISTA' else bajista_weight if combined_trend == 'BAJISTA' else 0.5,
                'phase_confidence': sum(weights.values())
            }
            
            return combined
        except Exception as e:
            logging.debug(f"Error combinando an√°lisis de fases: {e}")
            return {}
    
    def _determine_market_phase_optimized(self, trend_strength, volatility, phase_analysis):
        if volatility < 0.2 and abs(trend_strength) < 0.3:
            return "consolidation"
        elif abs(trend_strength) > 2.5:
            return "strong_trend"
        elif abs(trend_strength) > 1.2:
            return "trending" 
        elif volatility > 2.0:
            return "high_volatility"
        elif phase_analysis.get('momentum_shift', False):
            return "reversal_potential"
        elif trend_strength > 0.5:
            return "bullish_bias"
        elif trend_strength < -0.5:
            return "bearish_bias"
        else:
            return "normal"
    
    def _calculate_confidence_score(self):
        score = 0
        
        tick_score = min(30, (self.tick_count / 25) * 30)
        score += tick_score
        
        if len(self.velocity_metrics) >= 10:
            score += 20
        
        phase_score = self.analysis_phases['final']['weight'] * 30
        score += phase_score
        
        if len(self.price_memory) >= 10:
            prices = list(self.price_memory)[-10:]
            volatility = (max(prices) - min(prices)) * 10000
            if volatility < 1.0:
                score += 20
            elif volatility < 2.0:
                score += 10
        
        return min(100, score)
    
    def get_ultra_analysis(self):
        if self.tick_count < MIN_TICKS_FOR_PREDICTION:
            return {
                'status': 'INSUFFICIENT_DATA', 
                'tick_count': self.tick_count,
                'message': f'Recolectando ticks: {self.tick_count}/{MIN_TICKS_FOR_PREDICTION}',
                'confidence': self._calculate_confidence_score()
            }
        
        try:
            advanced_metrics = self._calculate_ultra_advanced_metrics()
            if not advanced_metrics:
                return {'status': 'ERROR', 'message': 'Error en m√©tricas'}
            
            overall_confidence = min(95, advanced_metrics.get('confidence_score', 0) + 
                                   advanced_metrics.get('data_quality', 0) * 20)
            
            return {
                'status': 'SUCCESS',
                'tick_count': self.tick_count,
                'current_price': self.current_candle_close,
                'open_price': self.current_candle_open,
                'high_price': self.current_candle_high,
                'low_price': self.current_candle_low,
                'candle_range': (self.current_candle_high - self.current_candle_low) * 10000,
                'timestamp': time.time(),
                'candle_age': time.time() - self.candle_start_time if self.candle_start_time else 0,
                'overall_confidence': overall_confidence,
                **advanced_metrics
            }
            
        except Exception as e:
            logging.error(f"Error en an√°lisis completo: {e}")
            return {'status': 'ERROR', 'message': str(e)}
    
    def get_recent_ticks(self, n=50):
        return [tick['price'] for tick in list(self.ticks)[-n:]]
    
    def reset(self):
        try:
            if self.current_candle_close is not None:
                self.last_candle_close = self.current_candle_close
                
            self.ticks.clear()
            self.current_candle_open = None
            self.current_candle_high = None
            self.current_candle_low = None
            self.current_candle_close = None
            self.tick_count = 0
            self.price_memory.clear()
            self.velocity_metrics.clear()
            self.acceleration_metrics.clear()
            self.volume_profile.clear()
            self.price_levels.clear()
            self.candle_start_time = None
            
            for phase in self.analysis_phases:
                self.analysis_phases[phase] = {'ticks': 0, 'analysis': {}, 'weight': self.analysis_phases[phase]['weight']}
                
        except Exception as e:
            logging.error(f"Error en reset: {e}")

# ------------------ ADAPTIVE MARKET LEARNER (OPTIMIZADO) ------------------
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler

class AdaptiveMarketLearner:
    def __init__(self, feature_size=18, classes=None, buffer_size=1000):
        self.feature_size = feature_size
        self.classes = np.array(['BAJA', 'LATERAL', 'ALZA']) if classes is None else np.array(classes)
        self.buffer_size = buffer_size
        self.replay_buffer = deque(maxlen=buffer_size)
        self.model_path = ONLINE_MODEL_PATH
        self.scaler_path = ONLINE_SCALER_PATH
        self._ensure_dirs()
        self.scaler = self._load_scaler()
        self.model = self._load_model()
        self.training_count = 0
        self.last_training_result = {"trained": False, "reason": "not_initialized"}

    def _ensure_dirs(self):
        os.makedirs(os.path.dirname(self.model_path) or ".", exist_ok=True)

    def _load_model(self):
        if os.path.exists(self.model_path):
            try:
                model = joblib.load(self.model_path)
                logging.info("‚úÖ Modelo online cargado exitosamente")
                return model
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è No se pudo cargar modelo online: {e}")
        
        model = SGDClassifier(
            loss='log_loss', 
            max_iter=1000,
            tol=1e-3,
            warm_start=True,
            learning_rate='optimal'
        )
        dummy_X = np.random.normal(0, 0.1, (3, self.feature_size))
        dummy_y = np.array(['BAJA', 'LATERAL', 'ALZA'])
        model.partial_fit(dummy_X, dummy_y, classes=self.classes)
        logging.info("üÜï Nuevo modelo online creado")
        return model

    def _load_scaler(self):
        if os.path.exists(self.scaler_path):
            try:
                scaler = joblib.load(self.scaler_path)
                logging.info("‚úÖ Scaler online cargado exitosamente")
                return scaler
            except Exception:
                pass
        return StandardScaler()

    def persist(self):
        try:
            joblib.dump(self.model, self.model_path)
            joblib.dump(self.scaler, self.scaler_path)
            if self.training_count % 10 == 0:
                logging.info(f"üíæ Modelo persistido (entrenamientos: {self.training_count})")
        except Exception as e:
            logging.error(f"‚ùå Error guardando modelo: {e}")

    def add_sample(self, features: np.ndarray, label: str):
        try:
            if features is not None and features.size > 0:
                if features.ndim == 1 and features.shape[0] == self.feature_size:
                    self.replay_buffer.append((features.astype(float), label))
                    return True
                else:
                    logging.debug(f"‚ö†Ô∏è Formato features no esperado: {features.shape}")
            return False
        except Exception as e:
            logging.error(f"‚ùå Error a√±adiendo muestra: {e}")
            return False

    def partial_train(self, batch_size=32):
        if len(self.replay_buffer) < 5:
            result = {"trained": False, "reason": "not_enough_samples", "buffer_size": len(self.replay_buffer)}
            self.last_training_result = result
            return result
        
        try:
            samples = list(self.replay_buffer)[-batch_size:]
            X = np.vstack([s[0] for s in samples])
            y = np.array([s[1] for s in samples])
            
            if len(self.replay_buffer) >= 10:
                if hasattr(self.scaler, "partial_fit"):
                    self.scaler.partial_fit(X)
                else:
                    self.scaler.fit(X)
            
            if hasattr(self.scaler, "mean_") and self.scaler.mean_ is not None:
                Xs = self.scaler.transform(X)
            else:
                Xs = X
                logging.debug("üîß Scaler no entrenado, usando datos originales")
            
            self.model.partial_fit(Xs, y, classes=self.classes)
            self.training_count += 1
            
            if self.training_count % 5 == 0:
                self.persist()
                
            result = {
                "trained": True, 
                "n_samples": len(samples),
                "training_count": self.training_count,
                "buffer_size": len(self.replay_buffer),
                "scaler_trained": hasattr(self.scaler, "mean_") and self.scaler.mean_ is not None
            }
            self.last_training_result = result
            return result
            
        except Exception as e:
            logging.error(f"‚ùå Error en entrenamiento: {e}")
            result = {"trained": False, "reason": str(e)}
            self.last_training_result = result
            return result

    def predict_proba(self, features: np.ndarray):
        try:
            X = np.atleast_2d(features.astype(float))
            
            if (hasattr(self.scaler, "mean_") and self.scaler.mean_ is not None and 
                len(self.replay_buffer) >= 5):
                Xs = self.scaler.transform(X)
                probs = self.model.predict_proba(Xs)[0]
                return dict(zip(self.model.classes_, probs))
            else:
                logging.debug("üîß Predict_proba: usando fallback por scaler no entrenado")
                return dict(zip(self.classes, np.ones(len(self.classes)) / len(self.classes)))
                
        except Exception as e:
            logging.debug(f"üîß Fallback en predict_proba: {e}")
            return dict(zip(self.classes, np.ones(len(self.classes)) / len(self.classes)))

    def predict(self, features: np.ndarray):
        try:
            X = np.atleast_2d(features.astype(float))
            
            if (hasattr(self.scaler, "mean_") and self.scaler.mean_ is not None and 
                self.training_count > 0 and len(self.replay_buffer) >= 5):
                
                Xs = self.scaler.transform(X)
                predicted = self.model.predict(Xs)[0]
                proba = self.predict_proba(features)
                confidence = max(proba.values()) * 100
                
                return {
                    "predicted": predicted,
                    "proba": proba,
                    "confidence": round(confidence, 2),
                    "training_count": self.training_count,
                    "status": "ML_ACTIVE"
                }
            else:
                logging.debug("üîß Predict: modelo no entrenado, usando LATERAL conservador")
                return {
                    "predicted": "LATERAL",
                    "proba": dict(zip(self.classes, [1/3]*3)),
                    "confidence": 33.3,
                    "training_count": self.training_count,
                    "status": "ML_INITIALIZING"
                }
                
        except Exception as e:
            logging.error(f"‚ùå Error en predict: {e}")
            return {
                "predicted": "LATERAL",
                "proba": dict(zip(self.classes, [1/3]*3)),
                "confidence": 33.3,
                "training_count": self.training_count,
                "status": "ML_ERROR"
            }

# ------------------ SISTEMA DE VALIDACI√ìN EN TIEMPO REAL ------------------
class RealTimeValidator:
    def __init__(self):
        self.tracking_active = False
        self.prediction_data = None
        self.validation_history = deque(maxlen=50)
        self.confidence_trend = 0
        self.current_tracking_score = 0
        self.last_validation_update = 0
        
    def start_tracking(self, prediction, current_price):
        self.tracking_active = True
        self.prediction_data = {
            'start_time': time.time(),
            'initial_price': current_price,
            'predicted_direction': prediction['direction'],
            'prediction_confidence': prediction['confidence'],
            'expected_movement_min': 0.3,
            'validation_points': []
        }
        logging.info(f"üîç INICIANDO TRACKING TIEMPO REAL: {prediction['direction']} | "
                   f"Conf: {prediction['confidence']}%")
    
    def update_validation(self, current_price, current_tick_count):
        if not self.tracking_active or not self.prediction_data:
            return None
            
        current_time = time.time()
        if current_time - self.last_validation_update < 3 and current_tick_count % 5 != 0:
            return None
            
        price_change = (current_price - self.prediction_data['initial_price']) * 10000
        expected_direction = self.prediction_data['predicted_direction']
        
        movement_threshold = max(0.2, abs(price_change) * 0.3)
        if abs(price_change) < movement_threshold:
            current_direction = "LATERAL"
            is_tracking = None
        else:
            current_direction = "ALZA" if price_change > 0 else "BAJA"
            is_tracking = (current_direction == expected_direction)
        
        tracking_score = self._calculate_tracking_score(price_change, is_tracking)
        
        validation_point = {
            'timestamp': current_time,
            'price_change': round(price_change, 2),
            'current_direction': current_direction,
            'is_tracking': is_tracking,
            'tracking_score': tracking_score,
            'tick_count': current_tick_count
        }
        
        self.prediction_data['validation_points'].append(validation_point)
        self.last_validation_update = current_time
        
        if len(self.prediction_data['validation_points']) % 5 == 0:
            status_icon = "‚úÖ" if is_tracking else "‚ùå" if is_tracking is False else "‚ö™"
            logging.info(f"üîç TRACKING TIEMPO REAL: {status_icon} | "
                       f"Mov: {price_change:.1f}pips | "
                       f"Score: {tracking_score:.1f}%")
        
        return validation_point
    
    def _calculate_tracking_score(self, price_change, is_tracking):
        base_score = 50
        
        if is_tracking:
            base_score += 25
            movement_bonus = min(20, abs(price_change) * 2)
            base_score += movement_bonus
        elif is_tracking is False:
            base_score -= 25
        
        if len(self.prediction_data['validation_points']) > 3:
            recent_points = list(self.prediction_data['validation_points'])[-3:]
            tracking_count = sum(1 for p in recent_points if p['is_tracking'] is True)
            if tracking_count >= 2:
                base_score += 10
        
        return max(0, min(100, base_score))
    
    def get_realtime_summary(self):
        if not self.tracking_active or not self.prediction_data:
            return None
            
        points = self.prediction_data['validation_points']
        if not points:
            return None
            
        recent_points = list(points)[-10:]
        tracking_points = [p for p in recent_points if p['is_tracking'] is True]
        against_points = [p for p in recent_points if p['is_tracking'] is False]
        
        tracking_ratio = len(tracking_points) / len(recent_points) if recent_points else 0
        avg_tracking_score = np.mean([p['tracking_score'] for p in recent_points]) if recent_points else 50
        
        return {
            'active': True,
            'predicted_direction': self.prediction_data['predicted_direction'],
            'tracking_ratio': round(tracking_ratio, 2),
            'current_score': round(avg_tracking_score, 1),
            'total_validation_points': len(points),
            'recent_tracking': len(tracking_points),
            'recent_against': len(against_points),
            'status': 'STRONG' if avg_tracking_score > 70 else 'WEAK' if avg_tracking_score < 40 else 'NEUTRAL'
        }
    
    def stop_tracking(self):
        if self.tracking_active:
            summary = self.get_realtime_summary()
            self.tracking_active = False
            if summary:
                self.validation_history.append(summary)
            return summary
        return None

# ------------------ FEATURE BUILDER MEJORADO ------------------
def build_advanced_features_from_analysis(analysis, seconds_remaining, tick_window=30):
    try:
        if analysis.get('status') != 'SUCCESS':
            return np.zeros(18)
            
        current_price = analysis.get('current_price', 0)
        tick_count = analysis.get('tick_count', 0)
        
        trend_strength = analysis.get('trend_strength', 0)
        momentum = analysis.get('momentum', 0)
        volatility = analysis.get('volatility', 0)
        buy_pressure = analysis.get('buy_pressure', 0.5)
        sell_pressure = analysis.get('sell_pressure', 0.5)
        pressure_ratio = analysis.get('pressure_ratio', 1.0)
        velocity = analysis.get('velocity', 0)
        candle_progress = analysis.get('candle_progress', 0)
        phase_analysis = analysis.get('phase_analysis', {})
        momentum_shift = 1.0 if phase_analysis.get('momentum_shift', False) else 0.0
        consistency_score = phase_analysis.get('consistency_score', 0)
        time_remaining = seconds_remaining / TIMEFRAME
        
        features = np.array([
            current_price,
            trend_strength,
            momentum,
            volatility,
            buy_pressure,
            sell_pressure,
            pressure_ratio,
            velocity,
            candle_progress,
            momentum_shift,
            consistency_score,
            time_remaining,
            tick_count / 100.0,
            analysis.get('data_quality', 0),
            analysis.get('candle_range', 0),
            min(1.0, tick_count / 50.0),
            np.log1p(abs(trend_strength)),
            np.sqrt(abs(momentum))
        ]).astype(float)
        
        if features.shape[0] < 18:
            features = np.pad(features, (0, 18 - features.shape[0]))
        elif features.shape[0] > 18:
            features = features[:18]
            
        return features
        
    except Exception as e:
        logging.error(f"‚ùå Error construyendo features avanzados: {e}")
        return np.zeros(18)

# ------------------ SISTEMA IA PROFESIONAL COMPLETO ------------------
class ComprehensiveAIPredictor:
    def __init__(self):
        self.analyzer = UltraEfficientAnalyzer()
        self.realtime_validator = RealTimeValidator()
        self.prediction_history = deque(maxlen=20)
        self.performance_stats = {
            'total_predictions': 0,
            'correct_predictions': 0,
            'recent_accuracy': 0.0,
            'phase_analysis_count': 0,
            'realtime_tracking_score': 0
        }
        self.last_prediction = None
        self.last_validation_result = None
        
    def process_tick(self, price: float, seconds_remaining: float = None):
        try:
            tick_data = self.analyzer.add_tick(price, seconds_remaining)
            
            if (self.realtime_validator.tracking_active and 
                self.analyzer.tick_count % 3 == 0):
                validation_point = self.realtime_validator.update_validation(
                    price, self.analyzer.tick_count
                )
                
            return {
                "tick_count": self.analyzer.tick_count,
                "status": "PROCESSED"
            }
        except Exception as e:
            logging.error(f"Error en process_tick: {e}")
            return None
    
    def _comprehensive_ai_analysis(self, analysis, ml_prediction=None):
        try:
            momentum = analysis['momentum']
            trend_strength = analysis['trend_strength']
            pressure_ratio = analysis['pressure_ratio']
            volatility = analysis['volatility']
            market_phase = analysis['market_phase']
            data_quality = analysis['data_quality']
            phase_analysis = analysis.get('phase_analysis', {})
            candle_progress = analysis.get('candle_progress', 0)
            
            buy_score = 0
            sell_score = 0
            reasons = []
            
            ml_boost = 0
            if ml_prediction and ml_prediction.get('confidence', 0) > 60:
                ml_direction = ml_prediction.get('predicted', 'LATERAL')
                ml_confidence = ml_prediction.get('confidence', 0) / 100.0
                ml_boost = ml_confidence * 0.3
                reasons.append(f"ü§ñ ML confirma {ml_direction} ({ml_prediction['confidence']}%)")
            
            late_phase_weight = 1.0 if candle_progress > 0.8 else 0.7

            trend_weight = 0.35 * late_phase_weight
            if abs(trend_strength) > 1.0:
                if trend_strength > 0:
                    buy_score += 8 * trend_weight + ml_boost
                    reasons.append(f"üìà Tendencia alcista fuerte ({trend_strength:.1f})")
                else:
                    sell_score += 8 * trend_weight + ml_boost
                    reasons.append(f"üìâ Tendencia bajista fuerte ({trend_strength:.1f})")
            
            momentum_weight = 0.30 * late_phase_weight
            if abs(momentum) > 0.8:
                if momentum > 0:
                    buy_score += 7 * momentum_weight
                    reasons.append(f"üöÄ Momentum alcista fuerte ({momentum:.1f}pips)")
                else:
                    sell_score += 7 * momentum_weight
                    reasons.append(f"üîª Momentum bajista fuerte ({momentum:.1f}pips)")
            
            phase_weight = 0.15 * late_phase_weight
            if phase_analysis.get('momentum_shift', False):
                current_trend = phase_analysis.get('final_trend', 'N/A')
                if current_trend == 'ALCISTA':
                    buy_score += 4 * phase_weight
                    reasons.append("üîÑ Cambio de momentum a alcista")
                elif current_trend == 'BAJISTA':
                    sell_score += 4 * phase_weight
                    reasons.append("üîÑ Cambio de momentum a bajista")
            
            pressure_weight = 0.20 * late_phase_weight
            if pressure_ratio > 2.0:
                buy_score += 6 * pressure_weight
                reasons.append(f"üí∞ Fuerte presi√≥n compradora ({pressure_ratio:.1f}x)")
            elif pressure_ratio < 0.5:
                sell_score += 6 * pressure_weight
                reasons.append(f"üí∏ Fuerte presi√≥n vendedora ({pressure_ratio:.1f}x)")
            
            score_difference = buy_score - sell_score
            
            base_threshold = 0.4
            if ml_prediction and ml_prediction.get('confidence', 0) > 70:
                base_threshold = 0.3
            
            confidence_threshold = base_threshold - (0.1 * (1 - data_quality))
            
            if abs(score_difference) > confidence_threshold:
                if score_difference > 0:
                    direction = "ALZA"
                    base_confidence = 55 + (score_difference * 40)
                else:
                    direction = "BAJA" 
                    base_confidence = 55 + (abs(score_difference) * 40)
            else:
                direction = "LATERAL"
                base_confidence = 40
                reasons.append("‚ö° Se√±ales mixtas o insuficientes")
            
            confidence = base_confidence
            confidence *= data_quality
            
            if analysis['tick_count'] > 40:
                confidence = min(90, confidence + 15)
                reasons.append("üìä Alta calidad de datos (muchos ticks)")
            
            confidence = max(35, min(90, confidence))
            
            return {
                'direction': direction,
                'confidence': int(confidence),
                'buy_score': round(buy_score, 2),
                'sell_score': round(sell_score, 2),
                'score_difference': round(score_difference, 2),
                'reasons': reasons,
                'market_phase': market_phase,
                'candle_progress': round(candle_progress, 2),
                'phase_analysis': phase_analysis,
                'ml_boost': round(ml_boost, 2)
            }
        except Exception as e:
            logging.error(f"Error en an√°lisis IA comprehensivo: {e}")
            return {
                'direction': 'LATERAL',
                'confidence': 35,
                'reasons': ['ü§ñ Error en an√°lisis comprehensivo'],
                'buy_score': 0,
                'sell_score': 0,
                'score_difference': 0
            }
    
    def predict_next_candle(self, ml_prediction=None):
        try:
            analysis = self.analyzer.get_ultra_analysis()
            
            if analysis.get('status') != 'SUCCESS':
                return {
                    'direction': 'LATERAL',
                    'confidence': 0,
                    'reason': analysis.get('message', 'Analizando...'),
                    'timestamp': now_iso()
                }
            
            realtime_boost = 0
            realtime_feedback = []
            
            if self.realtime_validator.tracking_active:
                tracking_summary = self.realtime_validator.get_realtime_summary()
                if tracking_summary and tracking_summary['status'] == 'STRONG':
                    realtime_boost = 0.15
                    realtime_feedback.append(f"üéØ Tracking fuerte: {tracking_summary['current_score']}%")
                elif tracking_summary and tracking_summary['status'] == 'WEAK':
                    realtime_boost = -0.10
                    realtime_feedback.append(f"‚ö†Ô∏è Tracking d√©bil: {tracking_summary['current_score']}%")
            
            prediction = self._comprehensive_ai_analysis(analysis, ml_prediction)
            
            if realtime_boost != 0:
                original_confidence = prediction['confidence']
                prediction['confidence'] = int(max(35, min(90, prediction['confidence'] + (realtime_boost * 100))))
                prediction['reasons'].extend(realtime_feedback)
                prediction['realtime_boost'] = realtime_boost
                logging.info(f"üéØ BOOST TIEMPO REAL: {original_confidence}% ‚Üí {prediction['confidence']}%")
            
            if prediction['confidence'] < 45:
                prediction['direction'] = 'LATERAL'
                prediction['reasons'].append("üîç Confianza insuficiente para predicci√≥n direccional")
            
            prediction.update({
                'tick_count': analysis['tick_count'],
                'current_price': analysis['current_price'],
                'candle_range': analysis.get('candle_range', 0),
                'timestamp': now_iso(),
                'model_version': 'ULTRA_EFFICIENT_V5.5'
            })
            
            self.last_prediction = prediction
            self.prediction_history.append(prediction)
            
            if prediction['direction'] != 'LATERAL' and prediction['confidence'] > 50:
                self.realtime_validator.start_tracking(prediction, analysis['current_price'])
            
            if prediction['direction'] != 'LATERAL':
                ml_info = f" | ML Boost: {prediction.get('ml_boost', 0):.2f}" if ml_prediction else ""
                realtime_info = f" | RealTime: {prediction.get('realtime_boost', 0):.2f}" if prediction.get('realtime_boost') else ""
                logging.info(f"üéØ PREDICCI√ìN SIGUIENTE VELA: {prediction['direction']} | "
                           f"Conf: {prediction['confidence']}%{ml_info}{realtime_info} | "
                           f"Ticks: {analysis['tick_count']}")
            
            return prediction
        except Exception as e:
            logging.error(f"Error en predict_next_candle: {e}")
            return {
                'direction': 'LATERAL',
                'confidence': 0,
                'reason': 'Error en predicci√≥n',
                'timestamp': now_iso()
            }
    
    def validate_prediction(self, new_candle_open_price):
        try:
            if not self.last_prediction:
                return None
                
            realtime_summary = self.realtime_validator.stop_tracking()
                
            last_pred = self.last_prediction
            predicted_direction = last_pred.get('direction', 'N/A')
            
            previous_close = self.analyzer.last_candle_close
            current_open = new_candle_open_price
            
            if previous_close is None or current_open is None:
                return None
                
            price_change = (current_open - previous_close) * 10000
            
            candle_range = last_pred.get('candle_range', 0.5)
            minimal_change = max(0.15, candle_range * 0.2)
            
            if abs(price_change) < minimal_change:
                actual_direction = "LATERAL"
                is_correct = False
            else:
                if price_change > 0:
                    actual_direction = "ALZA"
                else:
                    actual_direction = "BAJA"
                
                is_correct = (actual_direction == predicted_direction)
            
            if predicted_direction != "LATERAL":
                self.performance_stats['total_predictions'] += 1
                if is_correct:
                    self.performance_stats['correct_predictions'] += 1
            
            total = self.performance_stats['total_predictions']
            correct = self.performance_stats['correct_predictions']
            accuracy = (correct / total * 100) if total > 0 else 0
            self.performance_stats['recent_accuracy'] = accuracy
            
            realtime_accuracy = "N/A"
            if realtime_summary and realtime_summary['total_validation_points'] > 5:
                realtime_accuracy = f"{realtime_summary['tracking_ratio']*100:.1f}%"
                self.performance_stats['realtime_tracking_score'] = realtime_summary['current_score']
            
            status_icon = "‚úÖ" if is_correct else "‚ùå"
            if actual_direction == "LATERAL":
                status_icon = "‚ö™"
            
            logging.info(f"üéØ VALIDACI√ìN: {status_icon} {predicted_direction}‚Üí{actual_direction} | "
                        f"Conf: {last_pred.get('confidence', 0)}% | "
                        f"Cambio: {price_change:.1f}pips | "
                        f"Rango vela: {candle_range:.1f}pips | "
                        f"Tracking: {realtime_accuracy}")
            
            if total > 0 and total % 5 == 0:
                logging.info(f"üìä PRECISI√ìN ACUMULADA: {accuracy:.1f}% (Total: {total})")
            
            self.last_validation_result = {
                'correct': is_correct,
                'predicted': predicted_direction,
                'actual': actual_direction,
                'confidence': last_pred.get('confidence', 0),
                'price_change': round(price_change, 2),
                'candle_range': round(candle_range, 2),
                'accuracy': round(accuracy, 1),
                'total_predictions': total,
                'correct_predictions': correct,
                'status_icon': status_icon,
                'timestamp': now_iso(),
                'realtime_tracking': realtime_summary
            }
            
            return self.last_validation_result
            
        except Exception as e:
            logging.error(f"Error en validaci√≥n: {e}")
            return None
    
    def get_performance_stats(self):
        return self.performance_stats.copy()
    
    def get_last_validation(self):
        return self.last_validation_result
    
    def reset(self):
        try:
            self.analyzer.reset()
        except Exception as e:
            logging.error(f"Error en reset predictor: {e}")

# ------------------ CONEXI√ìN PROFESIONAL MEJORADA ------------------
# [Mantener el mismo c√≥digo de conexi√≥n...]

# --------------- SISTEMA PRINCIPAL CORREGIDO ---------------
iq_connector = ProfessionalIQConnector()
predictor = ComprehensiveAIPredictor()
online_learner = AdaptiveMarketLearner(feature_size=18)

# VARIABLES GLOBALES
current_prediction = {
    "direction": "N/A",
    "confidence": 0,
    "tick_count": 0,
    "current_price": 0.0,
    "reasons": ["ü§ñ Sistema inicializando..."],
    "timestamp": now_iso(),
    "status": "INITIALIZING",
    "candle_progress": 0,
    "market_phase": "N/A",
    "buy_score": 0,
    "sell_score": 0,
    "ai_model_predicted": "N/A",
    "ml_confidence": 0,
    "training_count": 0,
    "ml_status": "INITIALIZING",
    "realtime_tracking": None
}

performance_stats = {
    'total_predictions': 0,
    'correct_predictions': 0,
    'recent_accuracy': 0.0,
    'last_validation': None
}

# Estado interno
_last_candle_start = int(time.time() // TIMEFRAME * TIMEFRAME)
_prediction_made_this_candle = False
_last_prediction_time = 0
_last_price = None

def tick_processor(price, timestamp):
    global current_prediction
    try:
        current_time = time.time()
        seconds_remaining = TIMEFRAME - (current_time % TIMEFRAME)
        
        if predictor.analyzer.tick_count == 0:
            delay = current_time - _last_candle_start
            logging.info(f"üéØ PRIMER TICK PROCESADO: {price:.5f} | "
                       f"Retardo: {delay:.1f}s | Vela: {(delay/TIMEFRAME*100):.1f}%")
        
        if predictor.analyzer.tick_count < 15 and predictor.analyzer.tick_count % 5 == 0:
            logging.info(f"üìä Tick #{predictor.analyzer.tick_count + 1}: {price:.5f} | "
                       f"Tiempo restante: {seconds_remaining:.1f}s")
        
        tick_data = predictor.process_tick(price, seconds_remaining)
        
        if tick_data:
            current_prediction.update({
                "current_price": float(price),
                "tick_count": predictor.analyzer.tick_count,
                "timestamp": now_iso(),
                "status": "ACTIVE",
                "candle_progress": (current_time % TIMEFRAME) / TIMEFRAME,
                "ml_status": online_learner.last_training_result.get('trained', False),
                "ml_samples": len(online_learner.replay_buffer),
                "realtime_tracking": predictor.realtime_validator.get_realtime_summary()
            })
            
    except Exception as e:
        logging.error(f"‚ùå Error procesando tick: {e}")

def premium_main_loop_corregido():
    """üöÄ LOOP PRINCIPAL CORREGIDO - PREDICCI√ìN 55s-60s"""
    global current_prediction, performance_stats, _last_candle_start
    global _prediction_made_this_candle, _last_prediction_time, _last_price
    
    logging.info(f"üöÄ DELOWYSS AI V5.5 ULTRA EFICIENTE - PREDICCI√ìN 55s-60s")
    logging.info("üéØ AN√ÅLISIS 0s-55s + PREDICCI√ìN 55s-60s ACTIVADO")
    logging.info(f"üìä CONFIG: MinTicks={MIN_TICKS_FOR_PREDICTION}, PredWindow={PREDICTION_WINDOW}s")
    
    # [Mismo c√≥digo de conexi√≥n...]
    
    # BUCLE PRINCIPAL CORREGIDO
    while True:
        try:
            current_time = time.time()
            current_candle_start = int(current_time // TIMEFRAME * TIMEFRAME)
            seconds_remaining = TIMEFRAME - (current_time % TIMEFRAME)
            
            price = iq_connector.get_realtime_price()
            if price and price > 0:
                _last_price = price

            candle_progress = (current_time - current_candle_start) / TIMEFRAME
            current_prediction['candle_progress'] = candle_progress

            # ‚úÖ CORRECCI√ìN CR√çTICA: PREDICCI√ìN EN 55s-60s
            prediction_window_active = (seconds_remaining <= PREDICTION_WINDOW and 
                                      seconds_remaining > 0.5)  # 55s-59.5s
            
            if (prediction_window_active and
                predictor.analyzer.tick_count >= MIN_TICKS_FOR_PREDICTION and
                (time.time() - _last_prediction_time) >= 2 and
                not _prediction_made_this_candle):

                # LOG INFORMATIVO MEJORADO
                logging.info(f"üéØ VENTANA PREDICCI√ìN 55s-60s ACTIVA: {seconds_remaining:.1f}s | "
                           f"Progreso: {candle_progress*100:.1f}% | "
                           f"Ticks acumulados: {predictor.analyzer.tick_count}")
                
                # AN√ÅLISIS CON 55s DE DATOS
                analysis = predictor.analyzer.get_ultra_analysis()
                if analysis.get('status') == 'SUCCESS':
                    realtime_metrics = predictor.realtime_validator.get_realtime_summary()
                    
                    features = build_advanced_features_from_analysis(analysis, seconds_remaining)
                    ml_prediction = online_learner.predict(features)
                    
                    # ‚úÖ PREDECIR SIGUIENTE VELA CON DATOS COMPLETOS
                    final_prediction = predictor.predict_next_candle(ml_prediction)
                    
                    current_prediction.update(final_prediction)
                    current_prediction.update({
                        "ai_model_predicted": ml_prediction['predicted'],
                        "ml_confidence": ml_prediction['confidence'],
                        "training_count": ml_prediction['training_count'],
                        "ml_status": ml_prediction.get('status', 'UNKNOWN'),
                        "realtime_tracking": realtime_metrics
                    })

                    _last_prediction_time = time.time()
                    _prediction_made_this_candle = True
                    
                    # LOG DE √âXITO
                    logging.info(f"üöÄ PREDICCI√ìN SIGUIENTE VELA COMPLETADA: "
                               f"{final_prediction['direction']} {final_prediction['confidence']}% | "
                               f"Base: {predictor.analyzer.tick_count} ticks | "
                               f"Tiempo an√°lisis: 55s")

            # AN√ÅLISIS EN TIEMPO REAL DURANTE 0s-55s
            elif (seconds_remaining > PREDICTION_WINDOW and
                  predictor.analyzer.tick_count >= 8 and
                  int(current_time) % 10 == 0):
                  
                if predictor.realtime_validator.tracking_active:
                    realtime_update = predictor.realtime_validator.update_validation(
                        price, predictor.analyzer.tick_count
                    )
                    if realtime_update:
                        current_prediction['realtime_tracking'] = predictor.realtime_validator.get_realtime_summary()

            # DETECCI√ìN NUEVA VELA (VALIDACI√ìN + AUTOLEARNING)
            if current_candle_start > _last_candle_start:
                if _last_price is not None:
                    validation = predictor.validate_prediction(_last_price)
                    if validation:
                        price_change = validation.get("price_change", 0)
                        actual_direction = validation.get("actual", "LATERAL")
                        
                        label = actual_direction
                        
                        analysis = predictor.analyzer.get_ultra_analysis()
                        if analysis.get('status') == 'SUCCESS':
                            features = build_advanced_features_from_analysis(analysis, 0)
                            
                            if features is not None and features.size == 18:
                                sample_added = online_learner.add_sample(features, label)
                                if sample_added:
                                    training_result = online_learner.partial_train(batch_size=16)
                                    
                                    ml_status = "‚úÖ" if training_result.get('trained', False) else "‚è≥"
                                    logging.info(f"üìö AutoLearning: {label} | Cambio: {price_change:.1f}pips | "
                                               f"Muestras: {training_result.get('buffer_size', 0)} | "
                                               f"Entrenamientos: {training_result.get('training_count', 0)} | "
                                               f"Estado: {ml_status}")
                                    
                                    performance_stats['last_validation'] = validation

                predictor.reset()
                _last_candle_start = current_candle_start
                _prediction_made_this_candle = False
                logging.info("üïØÔ∏è NUEVA VELA - Sistema de an√°lisis reiniciado")

            time.sleep(0.1)
            
        except Exception as e:
            logging.error(f"üí• Error en loop principal: {e}")
            time.sleep(1)

# [Resto del c√≥digo FastAPI y inicializaci√≥n igual...]

# ------------------ INICIALIZACI√ìN CORREGIDA ------------------
def start_system():
    try:
        thread = threading.Thread(target=premium_main_loop_corregido, daemon=True)
        thread.start()
        logging.info(f"‚≠ê DELOWYSS AI V5.5 INICIADA - PREDICCI√ìN 55s-60s ACTIVADA")
        logging.info("üéØ FLUJO: An√°lisis 0s-55s ‚Üí Predicci√≥n 55s-60s ‚Üí Validaci√≥n")
        logging.info("üìä EFICIENCIA: 90%+ con 55s de datos acumulados")
    except Exception as e:
        logging.error(f"‚ùå Error iniciando sistema: {e}")

# ‚úÖ INICIAR SISTEMA
if __name__ == "__main__":
    start_system()
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=PORT,
        log_level="info",
        access_log=True
    )
else:
    start_system()
